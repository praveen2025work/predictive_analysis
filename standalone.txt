# Complete Standalone Market Analysis Report Generator
# standalone_market_report.py

"""
Professional Financial Balance Analysis Report Generator
========================================================

This standalone version includes all necessary components and handles missing dependencies gracefully.
Run this file directly to generate a comprehensive market analysis report.

Requirements: Only basic Python with pandas, numpy, matplotlib, and sklearn
"""

import subprocess
import sys
import warnings
warnings.filterwarnings('ignore')

def install_and_import():
    """Install required packages and import modules"""
    
    # Install packages
    packages = ['pandas', 'numpy', 'matplotlib', 'scikit-learn']
    print("ğŸ“¦ Installing required packages...")
    
    for package in packages:
        try:
            print(f"   Installing {package}...")
            subprocess.check_call([sys.executable, "-m", "pip", "install", package, "--quiet"])
            print(f"   âœ… {package} installed")
        except:
            print(f"   âš ï¸ Could not install {package}")
    
    # Import modules
    try:
        import pandas as pd
        import numpy as np
        import matplotlib.pyplot as plt
        from datetime import datetime, timedelta
        from sklearn.ensemble import RandomForestRegressor
        from sklearn.preprocessing import StandardScaler
        from sklearn.model_selection import train_test_split
        from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
        from typing import Dict, List, Any
        
        print("âœ… All modules imported successfully")
        return pd, np, plt, datetime, timedelta, RandomForestRegressor, StandardScaler, train_test_split, mean_absolute_error, mean_squared_error, r2_score, Dict, List, Any
    except ImportError as e:
        print(f"âŒ Import error: {e}")
        print("Please install required packages manually: pip install pandas numpy matplotlib scikit-learn")
        sys.exit(1)

# Import all required modules
pd, np, plt, datetime, timedelta, RandomForestRegressor, StandardScaler, train_test_split, mean_absolute_error, mean_squared_error, r2_score, Dict, List, Any = install_and_import()

class StandaloneBalancePredictor:
    """Standalone balance predictor with embedded functionality"""
    
    def __init__(self):
        self.model = None
        self.scaler = StandardScaler()
        self.feature_columns = [
            'DAYS_SINCE_EPOCH', 'JOURNAL_COUNT', 'JOURNAL_TOTAL_AMOUNT', 
            'JOURNAL_AVG_AMOUNT', 'MONTH', 'DAY_OF_WEEK', 'IS_WEEKEND', 'QUARTER'
        ]
        self.is_trained = False
        self.feature_importance = None
    
    def generate_realistic_data(self, n_records=1500):
        """Generate realistic financial data for analysis"""
        print("ğŸ“Š Generating realistic financial data...")
        
        # Date range spanning multiple years
        start_date = datetime(2020, 1, 1)
        end_date = datetime(2023, 12, 31)
        date_range = pd.date_range(start=start_date, end=end_date, freq='D')
        
        data = []
        book_ids = ['BOOK_001', 'BOOK_002', 'BOOK_003', 'BOOK_004', 'BOOK_005']
        
        for book_id in book_ids:
            current_balance = np.random.normal(100000, 20000)  # Starting balance
            
            for i, date in enumerate(date_range):
                if len(data) >= n_records:
                    break
                
                # Business logic for realistic patterns
                # Seasonal effects
                seasonal_factor = 1 + 0.15 * np.sin(2 * np.pi * date.timetuple().tm_yday / 365.25)
                
                # Day of week effects
                weekday_factor = 1.2 if date.weekday() < 5 else 0.6  # Higher weekday activity
                
                # Month-end effects
                month_end_factor = 1.3 if date.day >= 25 else 1.0
                
                # Generate journal activity
                base_entries = 8
                journal_count = max(1, int(np.random.poisson(base_entries * weekday_factor * month_end_factor)))
                
                # Generate journal amounts
                base_amount = 2000 * seasonal_factor
                journal_amounts = [
                    max(100, np.random.normal(base_amount, base_amount * 0.3))
                    for _ in range(journal_count)
                ]
                
                journal_total = sum(journal_amounts)
                journal_avg = np.mean(journal_amounts)
                
                # Update balance with business logic
                balance_impact = journal_total * 0.05  # 5% of journal activity affects balance
                random_change = np.random.normal(0, 1000)  # Daily random variation
                trend_factor = i * 2  # Small upward trend over time
                
                current_balance += balance_impact + random_change + trend_factor
                
                # Ensure balance doesn't go negative
                current_balance = max(10000, current_balance)
                
                data.append({
                    'DATE': date,
                    'SAP_BOOK_ID': book_id,
                    'BALANCE': round(current_balance, 2),
                    'JOURNAL_COUNT': journal_count,
                    'JOURNAL_TOTAL_AMOUNT': round(journal_total, 2),
                    'JOURNAL_AVG_AMOUNT': round(journal_avg, 2),
                    'JOURNAL_STD_AMOUNT': round(np.std(journal_amounts), 2),
                    'MONTH': date.month,
                    'QUARTER': (date.month - 1) // 3 + 1,
                    'DAY_OF_WEEK': date.weekday(),
                    'IS_WEEKEND': 1 if date.weekday() >= 5 else 0,
                    'DAYS_SINCE_EPOCH': (date - datetime(1970, 1, 1)).days,
                    'YEAR': date.year
                })
        
        df = pd.DataFrame(data)
        print(f"âœ… Generated {len(df)} realistic financial records")
        print(f"ğŸ“… Date range: {df['DATE'].min().strftime('%Y-%m-%d')} to {df['DATE'].max().strftime('%Y-%m-%d')}")
        print(f"ğŸ’° Balance range: ${df['BALANCE'].min():,.2f} to ${df['BALANCE'].max():,.2f}")
        
        return df
    
    def train_model(self, df):
        """Train the Random Forest model"""
        print("ğŸ¤– Training Random Forest balance prediction model...")
        
        # Prepare features
        feature_cols = [col for col in self.feature_columns if col in df.columns]
        
        # Split data by year
        train_df = df[df['YEAR'] <= 2022].copy()
        test_df = df[df['YEAR'] > 2022].copy()
        
        if len(train_df) == 0 or len(test_df) == 0:
            print("âš ï¸ Insufficient data for train/test split. Using random split.")
            train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)
        
        # Prepare features and target
        X_train = train_df[feature_cols].fillna(0)
        y_train = train_df['BALANCE'].fillna(train_df['BALANCE'].mean())
        X_test = test_df[feature_cols].fillna(0)
        y_test = test_df['BALANCE'].fillna(test_df['BALANCE'].mean())
        
        # Scale features
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # Train Random Forest
        self.model = RandomForestRegressor(
            n_estimators=100,
            max_depth=15,
            min_samples_split=5,
            min_samples_leaf=2,
            random_state=42,
            n_jobs=-1
        )
        
        self.model.fit(X_train_scaled, y_train)
        self.is_trained = True
        
        # Evaluate model
        y_pred = self.model.predict(X_test_scaled)
        mae = mean_absolute_error(y_test, y_pred)
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        r2 = r2_score(y_test, y_pred)
        
        print(f"âœ… Model trained successfully!")
        print(f"ğŸ“Š Performance Metrics:")
        print(f"   â€¢ Mean Absolute Error: ${mae:,.2f}")
        print(f"   â€¢ Root Mean Square Error: ${rmse:,.2f}")
        print(f"   â€¢ RÂ² Score: {r2:.3f}")
        
        # Feature importance
        self.feature_importance = pd.DataFrame({
            'feature': feature_cols,
            'importance': self.model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        print(f"\nğŸ” Top 5 Most Important Features:")
        for i, (_, row) in enumerate(self.feature_importance.head().iterrows(), 1):
            print(f"   {i}. {row['feature']}: {row['importance']:.3f}")
        
        return {
            'mae': mae,
            'rmse': rmse,
            'r2': r2,
            'feature_importance': self.feature_importance,
            'test_data': (X_test_scaled, y_test, y_pred, test_df)
        }
    
    def predict(self, input_data: Dict[str, Any]) -> float:
        """Make a balance prediction"""
        if not self.is_trained:
            raise ValueError("Model must be trained before making predictions")
        
        # Prepare feature vector
        feature_vector = []
        for col in self.feature_columns:
            feature_vector.append(input_data.get(col, 0))
        
        # Scale and predict
        feature_vector = np.array(feature_vector).reshape(1, -1)
        feature_vector_scaled = self.scaler.transform(feature_vector)
        prediction = self.model.predict(feature_vector_scaled)[0]
        
        return round(prediction, 2)

class ComprehensiveReportGenerator:
    """Professional market analysis report generator"""
    
    def __init__(self, predictor: StandaloneBalancePredictor):
        self.predictor = predictor
        self.current_date = datetime.now()
        self.current_month = self.current_date.month
        self.current_year = self.current_date.year
    
    def analyze_current_performance(self, df):
        """Analyze current month performance"""
        # Get current month data (or latest available)
        current_month_data = df[
            (df['DATE'].dt.month == self.current_month) & 
            (df['DATE'].dt.year == self.current_year)
        ]
        
        if len(current_month_data) == 0:
            # Use latest available month
            latest_date = df['DATE'].max()
            current_month_data = df[
                (df['DATE'].dt.month == latest_date.month) & 
                (df['DATE'].dt.year == latest_date.year)
            ]
        
        if len(current_month_data) == 0:
            # Use last 30 days
            cutoff_date = df['DATE'].max() - timedelta(days=30)
            current_month_data = df[df['DATE'] >= cutoff_date]
        
        # Calculate metrics
        daily_balances = current_month_data.groupby('DATE')['BALANCE'].sum()
        
        analysis = {
            'period': f"{current_month_data['DATE'].min().strftime('%B %Y')}",
            'total_balance': current_month_data['BALANCE'].sum(),
            'avg_daily_balance': daily_balances.mean(),
            'max_balance': daily_balances.max(),
            'min_balance': daily_balances.min(),
            'balance_trend': self._calculate_trend(daily_balances),
            'volatility': daily_balances.std(),
            'total_transactions': current_month_data['JOURNAL_COUNT'].sum(),
            'total_volume': current_month_data['JOURNAL_TOTAL_AMOUNT'].sum(),
            'avg_transaction_size': current_month_data['JOURNAL_AVG_AMOUNT'].mean(),
            'days_analyzed': len(daily_balances)
        }
        
        return analysis
    
    def generate_predictions(self, df, days_ahead=30):
        """Generate predictions for future periods"""
        if not self.predictor.is_trained:
            return {'error': 'Model not trained'}
        
        # Get latest data point
        latest_data = df.sort_values('DATE').tail(1).iloc[0]
        last_date = latest_data['DATE']
        
        predictions = []
        current_balance = latest_data['BALANCE']
        
        for i in range(1, days_ahead + 1):
            future_date = last_date + timedelta(days=i)
            
            # Estimate future journal activity
            seasonal_factor = 1 + 0.1 * np.sin(2 * np.pi * future_date.month / 12)
            weekday_factor = 1.0 if future_date.weekday() < 5 else 0.7
            
            estimated_journals = max(1, int(8 * seasonal_factor * weekday_factor))
            estimated_volume = 15000 * seasonal_factor * weekday_factor
            
            # Prepare prediction input
            input_data = {
                'DAYS_SINCE_EPOCH': (future_date - datetime(1970, 1, 1)).days,
                'JOURNAL_COUNT': estimated_journals,
                'JOURNAL_TOTAL_AMOUNT': estimated_volume,
                'JOURNAL_AVG_AMOUNT': estimated_volume / estimated_journals,
                'MONTH': future_date.month,
                'QUARTER': (future_date.month - 1) // 3 + 1,
                'DAY_OF_WEEK': future_date.weekday(),
                'IS_WEEKEND': 1 if future_date.weekday() >= 5 else 0
            }
            
            # Make prediction
            try:
                predicted_balance = self.predictor.predict(input_data)
                current_balance = predicted_balance  # Update for next iteration
                
                predictions.append({
                    'date': future_date,
                    'predicted_balance': predicted_balance,
                    'estimated_journals': estimated_journals,
                    'estimated_volume': estimated_volume
                })
            except Exception as e:
                print(f"âš ï¸ Prediction error for {future_date}: {e}")
                break
        
        if not predictions:
            return {'error': 'No predictions generated'}
        
        # Calculate prediction metrics
        predicted_balances = [p['predicted_balance'] for p in predictions]
        
        return {
            'predictions': predictions,
            'month_end_balance': predicted_balances[-1] if predicted_balances else 0,
            'avg_predicted_balance': np.mean(predicted_balances),
            'predicted_trend': self._calculate_trend(pd.Series(predicted_balances)),
            'prediction_volatility': np.std(predicted_balances),
            'confidence': 'High' if len(predictions) == days_ahead else 'Medium'
        }
    
    def compare_historical(self, df):
        """Compare with historical performance"""
        historical_analysis = []
        
        # Analyze last 3 years by month
        for year in range(self.current_year - 3, self.current_year + 1):
            for month in range(1, 13):
                month_data = df[
                    (df['DATE'].dt.year == year) & 
                    (df['DATE'].dt.month == month)
                ]
                
                if len(month_data) > 0:
                    daily_balances = month_data.groupby('DATE')['BALANCE'].sum()
                    historical_analysis.append({
                        'year': year,
                        'month': month,
                        'avg_balance': daily_balances.mean(),
                        'total_volume': month_data['JOURNAL_TOTAL_AMOUNT'].sum(),
                        'total_transactions': month_data['JOURNAL_COUNT'].sum(),
                        'volatility': daily_balances.std()
                    })
        
        # Current month comparison
        current_month_hist = [h for h in historical_analysis 
                             if h['month'] == self.current_month and h['year'] < self.current_year]
        
        if current_month_hist:
            avg_historical_balance = np.mean([h['avg_balance'] for h in current_month_hist])
            avg_historical_volume = np.mean([h['total_volume'] for h in current_month_hist])
        else:
            avg_historical_balance = df['BALANCE'].mean()
            avg_historical_volume = df['JOURNAL_TOTAL_AMOUNT'].sum() / len(df['YEAR'].unique())
        
        return {
            'historical_data': historical_analysis,
            'avg_historical_balance': avg_historical_balance,
            'avg_historical_volume': avg_historical_volume,
            'years_analyzed': len(set([h['year'] for h in historical_analysis]))
        }
    
    def identify_patterns(self, df):
        """Identify patterns and anomalies"""
        daily_balances = df.groupby('DATE')['BALANCE'].sum()
        
        # Seasonal patterns
        monthly_avg = df.groupby(df['DATE'].dt.month)['BALANCE'].mean()
        weekly_avg = df.groupby(df['DATE'].dt.dayofweek)['BALANCE'].mean()
        
        # Anomaly detection (simple statistical approach)
        balance_mean = daily_balances.mean()
        balance_std = daily_balances.std()
        threshold = 2.5 * balance_std
        
        anomalies = daily_balances[abs(daily_balances - balance_mean) > threshold]
        
        # Trend analysis
        recent_data = daily_balances.tail(60)  # Last 60 days
        trend = self._calculate_trend(recent_data)
        
        return {
            'monthly_patterns': {
                'strongest_month': monthly_avg.idxmax(),
                'weakest_month': monthly_avg.idxmin(),
                'monthly_variation': monthly_avg.std() / monthly_avg.mean()
            },
            'weekly_patterns': {
                'strongest_day': weekly_avg.idxmax(),
                'weakest_day': weekly_avg.idxmin(),
                'weekend_ratio': weekly_avg.iloc[5:].mean() / weekly_avg.iloc[:5].mean()
            },
            'anomalies': {
                'count': len(anomalies),
                'severity': 'High' if len(anomalies) > 10 else 'Medium' if len(anomalies) > 5 else 'Low',
                'recent_anomalies': len(anomalies[anomalies.index >= daily_balances.index[-30]])
            },
            'trends': {
                'recent_trend': trend,
                'volatility_level': 'High' if balance_std > balance_mean * 0.2 else 'Medium' if balance_std > balance_mean * 0.1 else 'Low'
            }
        }
    
    def assess_risks(self, current_analysis, predictions, patterns):
        """Assess various risk factors"""
        risks = []
        
        # Liquidity risk
        if predictions.get('month_end_balance', 0) < current_analysis.get('avg_daily_balance', 0) * 0.8:
            risks.append({
                'type': 'Liquidity Risk',
                'level': 'High',
                'description': 'Projected balance decline may impact liquidity'
            })
        
        # Volatility risk
        if patterns['trends']['volatility_level'] == 'High':
            risks.append({
                'type': 'Volatility Risk',
                'level': 'Medium',
                'description': 'High balance volatility detected'
            })
        
        # Operational risk
        if patterns['anomalies']['severity'] == 'High':
            risks.append({
                'type': 'Operational Risk',
                'level': 'Medium',
                'description': 'Multiple balance anomalies detected'
            })
        
        # Seasonal risk
        if patterns['monthly_patterns']['monthly_variation'] > 0.3:
            risks.append({
                'type': 'Seasonal Risk',
                'level': 'Low',
                'description': 'High seasonal variation in balances'
            })
        
        return risks
    
    def generate_recommendations(self, current_analysis, predictions, historical, patterns, risks):
        """Generate strategic recommendations"""
        recommendations = []
        
        # Performance-based recommendations
        if predictions.get('month_end_balance', 0) < current_analysis.get('avg_daily_balance', 0):
            recommendations.append({
                'category': 'Cash Flow Management',
                'priority': 'High',
                'recommendation': 'Monitor cash flow closely as balance projections show decline',
                'action': 'Review upcoming payments and accelerate receivables collection'
            })
        
        # Historical comparison recommendations
        if current_analysis.get('avg_daily_balance', 0) < historical.get('avg_historical_balance', 0) * 0.9:
            recommendations.append({
                'category': 'Performance Improvement',
                'priority': 'High',
                'recommendation': 'Current performance below historical average',
                'action': 'Analyze root causes and implement corrective measures'
            })
        
        # Risk-based recommendations
        high_risks = [r for r in risks if r['level'] == 'High']
        if high_risks:
            recommendations.append({
                'category': 'Risk Mitigation',
                'priority': 'High',
                'recommendation': f"Address {len(high_risks)} high-priority risk(s)",
                'action': 'Implement risk mitigation strategies and enhanced monitoring'
            })
        
        # Pattern-based recommendations
        if patterns['anomalies']['count'] > 5:
            recommendations.append({
                'category': 'Operational Excellence',
                'priority': 'Medium',
                'recommendation': 'Investigate source of balance anomalies',
                'action': 'Review transaction processing and implement quality controls'
            })
        
        # Seasonal recommendations
        current_month_strength = patterns['monthly_patterns']['strongest_month']
        if self.current_month != current_month_strength:
            recommendations.append({
                'category': 'Strategic Planning',
                'priority': 'Low',
                'recommendation': f"Prepare for seasonal variations (strongest month: {current_month_strength})",
                'action': 'Adjust cash management strategies for seasonal patterns'
            })
        
        return recommendations
    
    def create_professional_report(self, df):
        """Generate comprehensive professional report"""
        print("ğŸ“‹ Generating comprehensive market analysis report...")
        
        # Perform all analyses
        current_analysis = self.analyze_current_performance(df)
        predictions = self.generate_predictions(df, days_ahead=30)
        historical = self.compare_historical(df)
        patterns = self.identify_patterns(df)
        risks = self.assess_risks(current_analysis, predictions, patterns)
        recommendations = self.generate_recommendations(current_analysis, predictions, historical, patterns, risks)
        
        # Generate report
        report_date = datetime.now().strftime("%B %d, %Y")
        
        report = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                    COMPREHENSIVE FINANCIAL ANALYSIS REPORT                                        â•‘
â•‘                                           {report_date}                                                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

EXECUTIVE SUMMARY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Period Analyzed: {current_analysis['period']}
Report Generated: {report_date}

KEY METRICS:
â€¢ Current Average Daily Balance: ${current_analysis['avg_daily_balance']:,.2f}
â€¢ Projected Month-End Balance: ${predictions.get('month_end_balance', 0):,.2f}
â€¢ Balance Trend: {current_analysis['balance_trend']}
â€¢ Volatility Level: {patterns['trends']['volatility_level']}
â€¢ Risk Assessment: {len([r for r in risks if r['level'] == 'High'])} High-Priority Risk(s)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
1. CURRENT MONTH PERFORMANCE ANALYSIS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Analysis Period: {current_analysis['period']}
Days Analyzed: {current_analysis['days_analyzed']}

BALANCE PERFORMANCE:
â€¢ Total Portfolio Balance: ${current_analysis['total_balance']:,.2f}
â€¢ Average Daily Balance: ${current_analysis['avg_daily_balance']:,.2f}
â€¢ Maximum Balance: ${current_analysis['max_balance']:,.2f}
â€¢ Minimum Balance: ${current_analysis['min_balance']:,.2f}
â€¢ Balance Volatility: ${current_analysis['volatility']:,.2f}

TRANSACTION ACTIVITY:
â€¢ Total Transactions: {current_analysis['total_transactions']:,}
â€¢ Total Transaction Volume: ${current_analysis['total_volume']:,.2f}
â€¢ Average Transaction Size: ${current_analysis['avg_transaction_size']:,.2f}

TREND ANALYSIS:
â€¢ Current Trend: {current_analysis['balance_trend']}
â€¢ Volatility Assessment: {patterns['trends']['volatility_level']}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
2. PREDICTIVE INSIGHTS FOR REMAINDER OF MONTH
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

        if 'error' not in predictions:
            report += f"""
FORECAST SUMMARY:
â€¢ Projected Month-End Balance: ${predictions['month_end_balance']:,.2f}
â€¢ Expected Average Balance: ${predictions['avg_predicted_balance']:,.2f}
â€¢ Predicted Trend: {predictions['predicted_trend']}
â€¢ Forecast Volatility: ${predictions['prediction_volatility']:,.2f}
â€¢ Model Confidence: {predictions['confidence']}

PROJECTION DETAILS:
â€¢ Total Predictions Generated: {len(predictions['predictions'])}
â€¢ Forecast Period: {len(predictions['predictions'])} days ahead
â€¢ Model Reliability: Random Forest with {predictions['confidence']} confidence
"""
        else:
            report += f"""
FORECAST SUMMARY:
â€¢ Status: {predictions['error']}
â€¢ Recommendation: Ensure model is properly trained before generating forecasts
"""

        report += f"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
3. HISTORICAL PERFORMANCE COMPARISON
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Historical Analysis Period: {historical['years_analyzed']} years

HISTORICAL BENCHMARKS:
â€¢ Historical Average Balance: ${historical['avg_historical_balance']:,.2f}
â€¢ Historical Average Volume: ${historical['avg_historical_volume']:,.2f}

CURRENT VS HISTORICAL:
â€¢ Balance Performance: {((current_analysis['avg_daily_balance'] - historical['avg_historical_balance']) / historical['avg_historical_balance'] * 100):+.1f}% vs historical average
â€¢ Volume Performance: {((current_analysis['total_volume'] - historical['avg_historical_volume']) / historical['avg_historical_volume'] * 100):+.1f}% vs historical average

TREND ASSESSMENT:
â€¢ Performance Status: {'Above' if current_analysis['avg_daily_balance'] > historical['avg_historical_balance'] else 'Below'} historical benchmarks
â€¢ Historical Data Points: {len(historical['historical_data'])} monthly records analyzed

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
4. PATTERN ANALYSIS & ANOMALY DETECTION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SEASONAL PATTERNS:
â€¢ Strongest Performance Month: {patterns['monthly_patterns']['strongest_month']}
â€¢ Weakest Performance Month: {patterns['monthly_patterns']['weakest_month']}
â€¢ Monthly Variation Coefficient: {patterns['monthly_patterns']['monthly_variation']:.3f}

WEEKLY PATTERNS:
â€¢ Strongest Day: {['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'][patterns['weekly_patterns']['strongest_day']]}
â€¢ Weakest Day: {['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'][patterns['weekly_patterns']['weakest_day']]}
â€¢ Weekend Activity Ratio: {patterns['weekly_patterns']['weekend_ratio']:.2f}

ANOMALY DETECTION:
â€¢ Total Anomalies Detected: {patterns['anomalies']['count']}
â€¢ Anomaly Severity Level: {patterns['anomalies']['severity']}
â€¢ Recent Anomalies (Last 30 Days): {patterns['anomalies']['recent_anomalies']}

VOLATILITY ASSESSMENT:
â€¢ Overall Volatility Level: {patterns['trends']['volatility_level']}
â€¢ Recent Trend: {patterns['trends']['recent_trend']}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
5. RISK ASSESSMENT & MARKET FACTORS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

IDENTIFIED RISKS:"""

        if risks:
            for i, risk in enumerate(risks, 1):
                report += f"""
{i}. {risk['type']} - Level: {risk['level']}
   Description: {risk['description']}"""
        else:
            report += """
â€¢ No significant risks identified in current analysis period"""

        report += f"""

MARKET FACTORS:
â€¢ Current Month: {datetime.now().strftime('%B')} (Seasonality Impact: {'High' if patterns['monthly_patterns']['monthly_variation'] > 0.2 else 'Low'})
â€¢ Day-of-Week Effects: Weekend activity at {patterns['weekly_patterns']['weekend_ratio']:.0%} of weekday levels
â€¢ Volatility Environment: {patterns['trends']['volatility_level']} volatility market conditions

EXTERNAL CONSIDERATIONS:
â€¢ Quarter: Q{(self.current_month - 1) // 3 + 1} {self.current_year}
â€¢ Month-End Effects: {'High impact expected' if datetime.now().day >= 20 else 'Standard conditions'}
â€¢ Seasonal Position: {'Peak season' if self.current_month == patterns['monthly_patterns']['strongest_month'] else 'Off-peak season'}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
6. STRATEGIC RECOMMENDATIONS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Based on our comprehensive analysis, we recommend the following strategic actions:
"""

        for i, rec in enumerate(recommendations, 1):
            report += f"""
{i}. {rec['category'].upper()} - Priority: {rec['priority']}
   
   Recommendation: {rec['recommendation']}
   
   Suggested Action: {rec['action']}
"""

        report += f"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
IMPLEMENTATION ROADMAP
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

IMMEDIATE ACTIONS (Next 7 Days):"""
        
        high_priority_recs = [r for r in recommendations if r['priority'] == 'High']
        if high_priority_recs:
            for rec in high_priority_recs[:3]:
                report += f"""
â€¢ {rec['recommendation']}"""
        else:
            report += """
â€¢ Continue standard monitoring procedures
â€¢ Review forecast accuracy as new data becomes available"""

        report += f"""

SHORT-TERM ACTIONS (Next 30 Days):
â€¢ Implement enhanced monitoring for identified risk factors
â€¢ Review and adjust cash management strategies based on predictions
â€¢ Analyze root causes of any identified anomalies

LONG-TERM STRATEGIC INITIATIVES:
â€¢ Develop seasonal cash management strategies
â€¢ Enhance predictive modeling capabilities
â€¢ Implement automated risk monitoring systems

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
CONCLUSION & NEXT STEPS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

OVERALL ASSESSMENT:
â€¢ Financial Position: {'Strong' if len([r for r in risks if r['level'] == 'High']) == 0 else 'Requires Attention'}
â€¢ Predictive Accuracy: {predictions.get('confidence', 'Medium')} confidence level
â€¢ Risk Profile: {len(risks)} identified risk factors

MONITORING SCHEDULE:
â€¢ Daily: Balance monitoring and anomaly detection
â€¢ Weekly: Forecast accuracy review and model recalibration
â€¢ Monthly: Comprehensive performance analysis and strategy review

REPORT METHODOLOGY:
â€¢ Data Analysis Period: {current_analysis['days_analyzed']} days
â€¢ Prediction Model: Random Forest Regression
â€¢ Historical Comparison: {historical['years_analyzed']} years of data
â€¢ Anomaly Detection: Statistical threshold analysis

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Report Generated: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
Analysis Model: Standalone Random Forest Balance Predictor v1.0
Next Scheduled Report: {(datetime.now() + timedelta(days=7)).strftime("%Y-%m-%d")}
Contact: Financial Analysis Team

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
        
        return report
    
    def _calculate_trend(self, data_series):
        """Calculate trend direction and magnitude"""
        if len(data_series) < 2:
            return "Insufficient data"
        
        # Simple linear regression for trend
        x = np.arange(len(data_series))
        try:
            slope = np.polyfit(x, data_series.values, 1)[0]
            
            if abs(slope) < data_series.std() * 0.01:
                return "Stable"
            elif slope > 0:
                return f"Increasing (+${abs(slope):.0f}/day)"
            else:
                return f"Decreasing (-${abs(slope):.0f}/day)"
        except:
            return "Unable to determine trend"

def create_sample_charts(df, save_charts=True):
    """Create visualization charts for the report"""
    print("ğŸ“Š Creating analysis charts...")
    
    # Set up plotting
    plt.style.use('default')
    plt.rcParams['figure.facecolor'] = 'white'
    plt.rcParams['axes.grid'] = True
    
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    fig.suptitle('Financial Balance Analysis Dashboard', fontsize=16, fontweight='bold')
    
    # 1. Daily balance trend
    daily_balances = df.groupby('DATE')['BALANCE'].sum()
    axes[0, 0].plot(daily_balances.index, daily_balances.values, linewidth=2, color='blue')
    axes[0, 0].set_title('Daily Balance Trend')
    axes[0, 0].set_ylabel('Balance ($)')
    axes[0, 0].tick_params(axis='x', rotation=45)
    
    # 2. Monthly averages
    monthly_avg = df.groupby(df['DATE'].dt.to_period('M'))['BALANCE'].mean()
    axes[0, 1].bar(range(len(monthly_avg)), monthly_avg.values, color='lightblue')
    axes[0, 1].set_title('Monthly Average Balances')
    axes[0, 1].set_ylabel('Average Balance ($)')
    axes[0, 1].set_xticks(range(len(monthly_avg)))
    axes[0, 1].set_xticklabels([str(p)[:7] for p in monthly_avg.index], rotation=45)
    
    # 3. Balance distribution
    axes[0, 2].hist(df['BALANCE'], bins=30, alpha=0.7, color='green')
    axes[0, 2].set_title('Balance Distribution')
    axes[0, 2].set_xlabel('Balance ($)')
    axes[0, 2].set_ylabel('Frequency')
    
    # 4. Journal activity vs balance
    daily_data = df.groupby('DATE').agg({'BALANCE': 'sum', 'JOURNAL_COUNT': 'sum'})
    axes[1, 0].scatter(daily_data['JOURNAL_COUNT'], daily_data['BALANCE'], alpha=0.6, color='purple')
    axes[1, 0].set_title('Journal Activity vs Balance')
    axes[1, 0].set_xlabel('Daily Journal Entries')
    axes[1, 0].set_ylabel('Daily Balance ($)')
    
    # 5. Weekly patterns
    weekly_avg = df.groupby(df['DATE'].dt.dayofweek)['BALANCE'].mean()
    day_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']
    axes[1, 1].bar(range(7), weekly_avg.values, color='orange')
    axes[1, 1].set_title('Average Balance by Day of Week')
    axes[1, 1].set_xlabel('Day of Week')
    axes[1, 1].set_ylabel('Average Balance ($)')
    axes[1, 1].set_xticks(range(7))
    axes[1, 1].set_xticklabels(day_names)
    
    # 6. Volatility over time
    volatility = daily_balances.rolling(window=30).std()
    axes[1, 2].plot(volatility.index, volatility.values, color='red', linewidth=2)
    axes[1, 2].set_title('30-Day Rolling Volatility')
    axes[1, 2].set_ylabel('Balance Volatility ($)')
    axes[1, 2].tick_params(axis='x', rotation=45)
    
    plt.tight_layout()
    
    if save_charts:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"financial_analysis_charts_{timestamp}.png"
        try:
            plt.savefig(filename, dpi=300, bbox_inches='tight')
            print(f"ğŸ“ˆ Charts saved to: {filename}")
        except Exception as e:
            print(f"âš ï¸ Could not save charts: {e}")
    
    plt.show()
    return fig

def test_natural_language_predictions(predictor):
    """Test natural language prediction capabilities"""
    print("\nğŸ§  Testing Natural Language Prediction Interface...")
    print("=" * 60)
    
    test_cases = [
        "I have 15 journal entries this month with a total of $50,000",
        "20 transactions worth $75,000 on a Tuesday in March",
        "5 entries, $25,000 total, average $5,000 on Friday",
        "30 journal entries, total amount 100,000, it's December weekend"
    ]
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\n{i}. Testing: '{test_case}'")
        
        # Simple parsing logic (since we don't have OpenAI)
        import re
        numbers = re.findall(r'\d+(?:,\d{3})*(?:\.\d+)?', test_case)
        numbers = [float(n.replace(',', '')) for n in numbers]
        
        # Extract basic info
        input_data = {
            'JOURNAL_COUNT': int(numbers[0]) if len(numbers) > 0 else 10,
            'JOURNAL_TOTAL_AMOUNT': numbers[1] if len(numbers) > 1 else 25000,
            'JOURNAL_AVG_AMOUNT': numbers[1] / numbers[0] if len(numbers) >= 2 else 2500,
            'MONTH': 12 if 'december' in test_case.lower() else 3 if 'march' in test_case.lower() else 6,
            'QUARTER': 4 if 'december' in test_case.lower() else 1 if 'march' in test_case.lower() else 2,
            'DAY_OF_WEEK': 1 if 'tuesday' in test_case.lower() else 4 if 'friday' in test_case.lower() else 0,
            'IS_WEEKEND': 1 if 'weekend' in test_case.lower() or 'saturday' in test_case.lower() or 'sunday' in test_case.lower() else 0,
            'DAYS_SINCE_EPOCH': (datetime(2023, 6, 15) - datetime(1970, 1, 1)).days
        }
        
        try:
            prediction = predictor.predict(input_data)
            print(f"   âœ… Predicted Balance: ${prediction:,.2f}")
            print(f"   ğŸ“Š Input: {input_data['JOURNAL_COUNT']} entries, ${input_data['JOURNAL_TOTAL_AMOUNT']:,.0f} total")
        except Exception as e:
            print(f"   âŒ Prediction failed: {e}")

def run_model_validation(predictor, df):
    """Run comprehensive model validation"""
    print("\nğŸ”¬ Running Model Validation...")
    print("=" * 50)
    
    if not predictor.is_trained:
        print("âŒ Model not trained")
        return
    
    # Feature importance analysis
    print("\nğŸ“Š Feature Importance Analysis:")
    if predictor.feature_importance is not None:
        for i, (_, row) in enumerate(predictor.feature_importance.head(8).iterrows(), 1):
            print(f"   {i:2d}. {row['feature']:<25} {row['importance']:.4f}")
    
    # Sample predictions on recent data
    print("\nğŸ¯ Sample Predictions on Recent Data:")
    recent_data = df.tail(5)
    
    for i, (_, row) in enumerate(recent_data.iterrows(), 1):
        input_data = {col: row[col] for col in predictor.feature_columns if col in row}
        
        try:
            prediction = predictor.predict(input_data)
            actual = row['BALANCE']
            error = abs(prediction - actual)
            error_pct = (error / actual) * 100
            
            print(f"   {i}. Date: {row['DATE'].strftime('%Y-%m-%d')}")
            print(f"      Actual: ${actual:,.2f} | Predicted: ${prediction:,.2f} | Error: {error_pct:.1f}%")
        except Exception as e:
            print(f"   {i}. Prediction failed: {e}")

def main():
    """Main execution function"""
    print("ğŸš€ COMPREHENSIVE FINANCIAL ANALYSIS SYSTEM")
    print("=" * 70)
    print("This tool generates professional market analysis reports using Random Forest ML")
    print("=" * 70)
    
    try:
        # Initialize components
        print("\n1ï¸âƒ£ Initializing Balance Predictor...")
        predictor = StandaloneBalancePredictor()
        
        # Generate realistic data
        print("\n2ï¸âƒ£ Generating realistic financial data...")
        df = predictor.generate_realistic_data(n_records=2000)
        
        # Train model
        print("\n3ï¸âƒ£ Training Random Forest prediction model...")
        training_results = predictor.train_model(df)
        
        # Model validation
        run_model_validation(predictor, df)
        
        # Test natural language interface
        test_natural_language_predictions(predictor)
        
        # Create charts
        print("\n4ï¸âƒ£ Creating analysis charts...")
        create_sample_charts(df, save_charts=True)
        
        # Generate comprehensive report
        print("\n5ï¸âƒ£ Generating comprehensive market analysis report...")
        report_generator = ComprehensiveReportGenerator(predictor)
        report = report_generator.create_professional_report(df)
        
        # Display and save report
        print("\n" + "="*100)
        print("ğŸ“‹ COMPREHENSIVE FINANCIAL ANALYSIS REPORT")
        print("="*100)
        print(report)
        
        # Save report to file
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"comprehensive_financial_report_{timestamp}.txt"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(report)
            print(f"\nğŸ“„ Report saved to: {filename}")
        except Exception as e:
            print(f"âŒ Error saving report: {e}")
        
        print(f"\nâœ… Analysis complete! Generated:")
        print(f"   â€¢ Comprehensive market analysis report with all 6 required sections")
        print(f"   â€¢ Financial dashboard with 6 visualization charts")
        print(f"   â€¢ Random Forest model with {training_results['r2']:.1%} accuracy")
        print(f"   â€¢ Risk assessment with strategic recommendations")
        print(f"   â€¢ Natural language prediction interface")
        
        # Interactive usage instructions
        print(f"\nğŸ¯ System Ready for Interactive Use!")
        print(f"   â€¢ predictor: Make balance predictions")
        print(f"   â€¢ report_generator: Generate new reports")
        print(f"   â€¢ df: Access sample dataset ({len(df)} records)")
        print(f"   â€¢ training_results: Model performance metrics")
        
        return {
            'predictor': predictor,
            'report_generator': report_generator,
            'data': df,
            'report': report,
            'training_results': training_results
        }
        
    except Exception as e:
        print(f"\nâŒ Error in main execution: {e}")
        print("Please check that all required packages are installed:")
        print("pip install pandas numpy matplotlib scikit-learn")
        return None

def demo_custom_prediction():
    """Demonstrate custom prediction functionality"""
    print("\nğŸ¯ CUSTOM PREDICTION DEMO")
    print("=" * 40)
    
    # Example: Predict balance for specific scenario
    custom_scenario = {
        'DAYS_SINCE_EPOCH': (datetime(2024, 6, 15) - datetime(1970, 1, 1)).days,
        'JOURNAL_COUNT': 25,
        'JOURNAL_TOTAL_AMOUNT': 75000,
        'JOURNAL_AVG_AMOUNT': 3000,
        'MONTH': 6,
        'QUARTER': 2,
        'DAY_OF_WEEK': 3,  # Thursday
        'IS_WEEKEND': 0
    }
    
    print("Scenario: 25 journal entries worth $75,000 on a Thursday in June")
    print("Expected prediction: ~$150,000 - $200,000 (based on typical patterns)")
    
    return custom_scenario

# Allow running as standalone script
if __name__ == "__main__":
    print("Starting Comprehensive Financial Analysis System...")
    
    # Run main analysis
    results = main()
    
    if results:
        # Make components available for interactive use
        predictor = results['predictor']
        report_generator = results['report_generator']
        df = results['data']
        report = results['report']
        training_results = results['training_results']
        
        # Demo custom prediction
        custom_scenario = demo_custom_prediction()
        
        print(f"\nğŸ‰ SUCCESS! The system is now ready.")
        print(f"ğŸ“Š Dataset: {len(df)} financial records from {df['DATE'].min().strftime('%Y-%m-%d')} to {df['DATE'].max().strftime('%Y-%m-%d')}")
        print(f"ğŸ¤– Model: Random Forest with {training_results['r2']:.1%} RÂ² score")
        print(f"ğŸ“‹ Report: Complete 6-section professional analysis")
        print(f"ğŸ“ˆ Charts: 6 visualization dashboards saved")
        
        print(f"\nğŸ’¡ Try making a custom prediction:")
        print(f"   prediction = predictor.predict(custom_scenario)")
        print(f"   print(f'Predicted balance: ${{prediction:,.2f}}')")
    else:
        print("âŒ System initialization failed. Please check dependencies.")
